# Classify and Detoxify: Tackling Toxic Comments with RoBERTa and LLaMA

![image](https://github.com/user-attachments/assets/89129e03-7253-40ea-aa77-a1a4163d3303)
![image](https://github.com/user-attachments/assets/a523894a-802b-4a3f-986d-18f5bcf54c12)

## Anggota Tim
| Nama       | NRP        | Github  |
|------------|------------|---------|
| Nixon Castroman     | 5025231024 | https://github.com/XoXonn |
| Hans Sanjaya Yantono | 5025231034 | https://github.com/hansits034 |

## Deskripsi Singkat Project
In this project, we developed a two-stage NLP system that first classifies toxic content and then detoxifies it â€” rephrasing harmful comments into softer, more respectful versions while preserving the original meaning.
We built and deployed the system using Gradio and Google Colab, with the model also uploaded and accesible on Hugging Face.
This project aims to promote healthier online communication by offering an automated solution to detect and transform toxic language instead of removing it.

## Our Complete Article
https://medium.com/@nixoncastroman08/classify-and-detoxify-tackling-toxic-comments-with-roberta-and-llama-99754e127d94

## Reference
1. https://github.com/s-nlp/detox?source=post_page-----99754e127d94---------------------------------------
